import itertools
import tempfile
import pickle


def __read_pickle_file(f):
    f.seek(0)
    while True:
        try:
            yield pickle.load(f)
        except EOFError:
            break


def iter_chunks(iterable, n):
    """
    Iterates over an iterable in chunks of size n.
    Args:
        iterable:   The iterable to iterate over.
        n:  The chunk size.
    Returns:
        A generator which will yield the entire iterable in chunks of size n.
    """
    it = iter(iterable)
    while True:
        chunk = list(itertools.islice(it, n))
        if not chunk:
            return
        yield chunk


def iter_len(iterable):
    """
    Counts the length of an iterable.
    Will exhaust the iterable as it is counting, and return a copy which will
    yeild the same items.
    """
    len_ = 0
    f = tempfile.TemporaryFile()
    for i in iterable:
        len_ += 1
        pickle.dump(i, f)

    f.seek(0)
    it = __read_pickle_file(f)
    return it, len_


def repeatable_generator(func):
    """
    Decorator to create a repeatable function from another function.
    Creates a wrapper class that calls the supplied function when data has
    been exhausted from any previous iteration.
    Useful for example when there is a need to repeat a generator multiple
    times but there is not enough RAM to use itertools.cycle.

    Example usage:

        @repeatable_generator
        def gen():
            for i in [1, 2, 3]:
                yield i

        g = gen()
        for i in g: # Calls gen
            print(i) # prints 1, 2, 3

        for i in g: # New call to gen
            print(i)

    Params:
        func: the generator function to be repeated.
    Returns:
        A instance of a class that implements an __iter__ function that calls
        func every time with the original parameters.
    """
    # Wrapper function to be able to catch self if the repeatable function is
    # part of a class.
    def wrapper(*args, **kwargs):
        class _repeat(object):
            def __init__(self, *args, **kwargs):
                self.__args = args
                self.__kwargs = kwargs

            def __iter__(self):
                return func(*self.__args, **self.__kwargs)
        return _repeat(*args, **kwargs)
    return wrapper


def repeat_gen(gen):
    """
    Repeats the generator externally.
    The data generated by gen has to be pickleable for the function to be
    usable.
    Will make a pass through the data before the generator is constructed which
    will cause an initial waiting time.
    """
    f = tempfile.TemporaryFile()
    for g in gen:
        pickle.dump(g, f)

    class _repeat(object):
        def __init__(self, _file):
            self._f = _file

        def __iter__(self):
            self._f.seek(0)
            while True:
                try:
                    yield pickle.load(self._f)
                except EOFError:
                    raise StopIteration
    return _repeat(f)


def iter_split(iterable, indexes):
    """
    Creates multiple generators from a single iterable which only yields part
    of the original iterable each.
    The original iterable must yield subscriptable data and indexes must only
    contain indexes that are in range of the data the iterable yields.
    The data must be pickleable for the function to work.

    Will make a pass through the data once to create the files for the
    generators to work with.

    Example:
    iterable yields the data [(1,2,3), (1,2,3)...] and indexes contain [0,2].
    2 generators will be returned [g_0, g_1] which will yield [1,1,...], and
    [3,3,...] respectively.

    Args:
        iterable: The iterable to split into several generators.
        indexes:  The indexes to yield from the data that is yielded from the
                  original iterable.
    Returns:
        Several generators as a list. Each generator i yields the data at index
        i from the original iterable.
    """
    def read(f):
        f.seek(0)
        while True:
            try:
                yield pickle.load(f)
            except EOFError:
                raise StopIteration

    files = [tempfile.TemporaryFile() for _ in indexes]
    for g in iterable:
        for (i, index) in enumerate(indexes):
            pickle.dump(g[index], files[i])

    gens = []
    for f in files:
        gens.append(read(f))
    return tuple(gens)
